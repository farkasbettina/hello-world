{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The problem of Colonel Kurtz (Stachurski Ch. 5)\n",
    "\n",
    "- $ W_t \\in \\{ 0, \\ldots, B \\} $ is the random quantity of fish Kurtz can catch in the morning of day $t$. distributed with pdf $\\phi$ iid over time.\n",
    "- $X_t$ Stock of fish at noon of day $t$.\n",
    "- $C_t$ fish consumption on the afternoon of day $t$\n",
    "- $R_t$ remainder of fish after consumption, which is frozen.\n",
    "Therefore, the evolution of the state variable $X$ is governed by\n",
    "$$ X' = R + W = X - C + W $$\n",
    "Thus, we have defined a state space $\\mathcal{X} = \\{ 0, \\ldots, M+B \\}$.\n",
    "\n",
    "Every day, after cataching $W_t$ fish, the Colonel decides how much to save $R_t = a(X_t)$. Note that we are considering stationary policies that take the form of a function $ a: \\mathcal{X} \\rightarrow \\mathcal{A} = \\{ 0, \\ldots, M+B \\}$. The problem can be written as\n",
    "$$\n",
    "\\max_a  E [\\rho ^t u(X_t - a(X_t)] = \\max_a  E [\\rho ^t u(C_t)]\n",
    "$$\n",
    "subject to\n",
    "$$ X' = a(X) + W' $$\n",
    "\n",
    "giving the familiar Bellman equation:\n",
    "$$\n",
    "V(X) = \\max_{a \\in \\Gamma(X)} u(X-a) + \\rho \\int V(X')dQ(X'|a,X)\n",
    "$$\n",
    "\n",
    "where $\\Gamma(X)$ is the set of available actions when the sate is $X$. That is, $\\Gamma(x) = \\{ 0,1,\\ldots, \\min\\{x,M\\} \\}$.    Note that $q(\\cdot|a,X)$ is fully determined by $a$ and $\\phi$, so we can rewrite the Bellman equation as:\n",
    "$$\n",
    "V(x) = \\max_a [  u(X-a) + \\rho \\sum_{z=0} ^B V(a+z)\\phi(z)  ]\n",
    "$$\n",
    "\n",
    "We solve (not estimate) the Colonel's problem (finding the optimal stationary policy and the correponding value function) using both value function iteration and policy iteration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global beta rho B M S Z\n",
    "beta = 0.5; % flow utility parameter\n",
    "rho = 0.9;\n",
    "B = 10;\n",
    "M = 5;\n",
    "S = [0:B+M];  % State space = 0,...,B + M\n",
    "Z = [0:B];    % Shock space = 0,...,B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Function Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = zeros(1, 16); \n",
    "err = 1;\n",
    "figure()\n",
    "while err > 10^-6\n",
    "    [vNew,alpha] = bellman(v);\n",
    "    err = max(abs(vNew - v));\n",
    "    v = vNew;\n",
    "    hold on;\n",
    "    plot(v);\n",
    "end\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphaIn = zeros(1,16);\n",
    "figure()\n",
    "while 0~=1\n",
    "    v_alpha = policyEval(alphaIn);\n",
    "    hold on;\n",
    "    plot(v_alpha);\n",
    "    [~, alphaOut] = bellman(v_alpha);\n",
    "    if alphaIn==alphaOut\n",
    "        break\n",
    "    else\n",
    "       alphaIn=alphaOut;\n",
    "    end\n",
    "end\n",
    "alphaOut"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Matlab",
   "language": "matlab",
   "name": "matlab"
  },
  "language_info": {
   "codemirror_mode": "octave",
   "file_extension": ".m",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "matlab",
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
